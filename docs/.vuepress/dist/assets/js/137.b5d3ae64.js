(window.webpackJsonp=window.webpackJsonp||[]).push([[137],{344:function(s,t,a){"use strict";a.r(t);var n=a(0),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h1",{attrs:{id:"tensorflow"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tensorflow"}},[s._v("#")]),s._v(" Tensorflow")]),s._v(" "),a("h2",{attrs:{id:"tensorboard里面显示图片"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tensorboard里面显示图片"}},[s._v("#")]),s._v(" Tensorboard里面显示图片")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" tensorflow "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" tf\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 获取图片数据")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("file")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("open")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'1.png'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'rb'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ndata "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("file")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("read"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("file")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("close"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 图片处理")]),s._v("\nimage "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("image"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("decode_png"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" channels"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nimage "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("expand_dims"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("image"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 添加到日志中")]),s._v("\nsess "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Session"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nwriter "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("summary"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("FileWriter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'logs'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nsummary_op "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("summary"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("image"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"image1"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" image"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 运行并写入日志")]),s._v("\nsummary "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" sess"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("summary_op"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nwriter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add_summary"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("summary"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 关闭")]),s._v("\nwriter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("close"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nsess"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("close"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br")])]),a("h2",{attrs:{id:"断点续训功能"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#断点续训功能"}},[s._v("#")]),s._v(" 断点续训功能")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("        \n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("saver "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Saver"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# To Save Trainning Process")]),s._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("MODEL_SAVE_PATH "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'./model/'")]),s._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("MODEL_NAME"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'fitNN_model'")]),s._v("\n        \n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Restore Last Training Model ")]),s._v("\n        ckpt "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_checkpoint_state"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("MODEL_SAVE_PATH"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" ckpt "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("and")]),s._v(" ckpt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("model_checkpoint_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("saver"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("restore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sess"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ckpt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("model_checkpoint_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Model Restored."')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" it "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("nIter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Train")]),s._v("\n        \n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" it "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("saver"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("save"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sess"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("join"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("MODEL_SAVE_PATH"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("MODEL_NAME"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br")])]),a("p",[s._v("运行成功之后，在命令行中执行:")]),s._v(" "),a("p",[a("code",[s._v("tensorboard --logdir=LOGPATH")]),s._v(" 即可打开 Tensorboard")]),s._v(" "),a("h2",{attrs:{id:"如何在保存-恢复多个网络模型的快照"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何在保存-恢复多个网络模型的快照"}},[s._v("#")]),s._v(" 如何在保存/恢复多个网络模型的快照?")]),s._v(" "),a("p",[s._v("保存")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Saver to save all the variables")]),s._v("\nmodel_save_path "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'./model/'")]),s._v("\nmodel_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'gail'")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# max_to_keep表示你想要保存的快照数目")]),s._v("\nsaver "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Saver"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("max_to_keep"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("120")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("with")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Session"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" sess"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" episode "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("max_episode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" episode "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("and")]),s._v(" episode "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# global_step可以帮你自动命名")]),s._v("\n            saver"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("save"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sess"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("join"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("model_save_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" model_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" global_step"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("episode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br")])]),a("p",[s._v("恢复")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Saver to save all the variables")]),s._v("\nmodel_save_path "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'./model/'")]),s._v("\nmodel_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'gail'")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# saver = tf.train.import_meta_graph(os.path.join(model_save_path,model_name+'-9600.meta'))")]),s._v("\nsaver "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Saver"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \nckpt "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_checkpoint_state"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("model_save_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" ckpt "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("and")]),s._v(" ckpt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("model_checkpoint_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Found Saved Model.'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 指定使用哪一个时刻训练好的模型")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# [-1]:代表最新的")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# [0]: 代表最老的")]),s._v("\n        ckpt_to_restore "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ckpt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("all_model_checkpoint_paths"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'No Saved Model. Exiting'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    exit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("with")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Session"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" sess"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    sess"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("global_variables_initializer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Restore Model")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" ckpt "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("and")]),s._v(" ckpt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("model_checkpoint_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        saver"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("restore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sess"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("ckpt_to_restore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Model Restored.'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br")])]),a("h2",{attrs:{id:"如何查看checkpoint里面保存了哪些变量"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何查看checkpoint里面保存了哪些变量"}},[s._v("#")]),s._v(" 如何查看checkpoint里面保存了哪些变量?")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" tensorflow"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("python"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tools"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("inspect_checkpoint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" print_tensors_in_checkpoint_file\nprint_tensors_in_checkpoint_file"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ckpt_to_restore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" all_tensors"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" tensor_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("''")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[a("a",{attrs:{href:"https://stackoverflow.com/questions/38218174/how-do-i-find-the-variable-names-and-values-that-are-saved-in-a-checkpoint",target:"_blank",rel:"noopener noreferrer"}},[s._v("How do I find the variable names and values that are saved in a checkpoint?\n"),a("OutboundLink")],1)]),s._v(" "),a("h2",{attrs:{id:"如何使用scope-name-恢复部分保存的变量"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何使用scope-name-恢复部分保存的变量"}},[s._v("#")]),s._v(" 如何使用scope name 恢复部分保存的变量?")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Restore only discriminator")]),s._v("\nsaver "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Saver"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("var_list"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_collection"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("GraphKeys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("GLOBAL_VARIABLES"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" scope"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'discriminator'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[a("strong",[s._v("参考:")]),s._v(" "),a("a",{attrs:{href:"https://stackoverflow.com/questions/42546365/how-to-restore-variables-of-a-particular-scope-from-a-saved-checkpoint-in-tensor/42977504",target:"_blank",rel:"noopener noreferrer"}},[s._v("How to restore variables of a particular scope from a saved checkpoint in tensorflow?"),a("OutboundLink")],1)]),s._v(" "),a("h2",{attrs:{id:"切片"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#切片"}},[s._v("#")]),s._v(" 切片")]),s._v(" "),a("p",[s._v("Tensorflow支持numpy形式的切片\n举例说明:")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 例子1")]),s._v("\n x "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Variable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("truncated_normal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("shape"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n y "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n sess "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("InteractiveSession"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("global_variables_initializer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("eval")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape\n "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#output")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#(10, 100)")]),s._v("\n \n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 例子2")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" tensorflow "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" tf\n x "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("constant"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n y1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 提取第一列元素(返回值的维数是2维)")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# y1 = x[:,0] # 若是这样维数是1维")]),s._v("\n sess "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Session"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n sess"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#array([[1, 2, 3],")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#      [4, 5, 6],")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#      [7, 8, 9]], dtype=int32)")]),s._v("\n sess"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#array([[1],")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#      [4],")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#      [7]], dtype=int32)")]),s._v("\n \n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br")])]),a("h2",{attrs:{id:"查看tensorfow是否使用的是gpu版本"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#查看tensorfow是否使用的是gpu版本"}},[s._v("#")]),s._v(" 查看Tensorfow是否使用的是GPU版本")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" tensorflow "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" tf\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("gpu_device_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Default GPU Device: {}'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("format")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("gpu_device_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Please install GPU version of TF"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br")])]),a("p",[s._v("若是，那么通常会输出如下的结果:")]),s._v(" "),a("p",[a("code",[s._v("Default GPU Device: /device:GPU:0")])]),s._v(" "),a("h2",{attrs:{id:"在tensorflow中添加观察项，便于观察训练结果"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#在tensorflow中添加观察项，便于观察训练结果"}},[s._v("#")]),s._v(" 在Tensorflow中添加观察项，便于观察训练结果")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 第零步: 在要观察的值附近修改成下面的格式")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("with")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name_scope"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'loss'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("loss "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("losses"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mean_squared_error"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("labels"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tfy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" predictions"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("out"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("summary"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("scalar"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'loss'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 第一步: 在全局初始化前加上两句")]),s._v("\nself"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("merged "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("summary"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("merge_all"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nself"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("writer "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("summary"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("FileWriter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"logs/"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sess"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("graph"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nself"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sess"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("global_variables_initializer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 第三步:在训练的过程中不断添加记录")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" \n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'train loss: '")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" train_loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    vgg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("save"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'./model/transfer_learn'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Model Updated"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    result "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" vgg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sess"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("vgg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("merged"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("feed_dict"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("vgg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tfx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" xs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("b_idx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" vgg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tfy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" ys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("b_idx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    vgg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("writer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add_summary"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br")])]),a("h2",{attrs:{id:"loss降不下去可能的原因"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#loss降不下去可能的原因"}},[s._v("#")]),s._v(" loss降不下去可能的原因")]),s._v(" "),a("ul",[a("li",[s._v("每次的Minibatch都随便给")]),s._v(" "),a("li",[s._v("参数不够")]),s._v(" "),a("li")]),s._v(" "),a("p",[s._v("loss一会很高一会很低")]),s._v(" "),a("h2",{attrs:{id:"tensorfow-gpu-版本的依赖"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tensorfow-gpu-版本的依赖"}},[s._v("#")]),s._v(" Tensorfow GPU 版本的依赖")]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html\nCUDA Toolkit\tLinux x86_64 Driver Version\tWindows x86_64 Driver Version\nCUDA 10.1.105\t>= 418.39\t>= 418.96\nCUDA 10.0.130\t>= 410.48\t>= 411.31\nCUDA 9.2 (9.2.148 Update 1)\t>= 396.37\t>= 398.26\nCUDA 9.2 (9.2.88)\t>= 396.26\t>= 397.44\nCUDA 9.1 (9.1.85)\t>= 390.46\t>= 391.29\nCUDA 9.0 (9.0.76)\t>= 384.81\t>= 385.54\nCUDA 8.0 (8.0.61 GA2)\t>= 375.26\t>= 376.51\nCUDA 8.0 (8.0.44)\t>= 367.48\t>= 369.30\nCUDA 7.5 (7.5.16)\t>= 352.31\t>= 353.66\nCUDA 7.0 (7.0.28)\t>= 346.46\t>= 347.62\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br")])]),a("h2",{attrs:{id:"如何在tf-keras中保存和加载训练模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何在tf-keras中保存和加载训练模型"}},[s._v("#")]),s._v(" 如何在tf.keras中保存和加载训练模型?")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" tensorflow"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("keras "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" models"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" layers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" optimizers\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("create_model")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n\t\tmodel "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Sequential"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n\t\t\tlayers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Dense"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" input_dim"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("obervation_space"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" activation"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'relu'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n\t\t\tlayers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Dense"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("action_space"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" activation"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'linear'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\t\t\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\t\tmodel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("compile")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("loss"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'mean_squared_error'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" optimizer "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" optimizers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Adam"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("lr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" model \n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("save_model")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" file_path"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'MountainCar-v0-dqn.h5'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'model saved'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\t\tself"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("save"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("file_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("load_model")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" models"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("load_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'./MountainCar-v0-dqn.h5'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("compile")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br")])]),a("h2",{attrs:{id:"如何使用tf-one-hot"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何使用tf-one-hot"}},[s._v("#")]),s._v(" 如何使用tf.one_hot()?")]),s._v(" "),a("p",[s._v("在处理的训练数据的标签时，往往需要把标签变成one_hot的形式，在Tensorflow里面可以这样处理。")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" tensorflow "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" tf\nlabels "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\nn_labels "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v("\nlabels_one_hot "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("one_hot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("labels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("n_labels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nsess "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Session"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nresult "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" sess"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("labels_one_hot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br")])]),a("p",[s._v("得到的结果:")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("."),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("."),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("."),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("."),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("."),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("."),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("."),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("."),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("."),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("."),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br")])]),a("h2",{attrs:{id:"如何安装tensorflow2-0"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何安装tensorflow2-0"}},[s._v("#")]),s._v(" 如何安装Tensorflow2.0?")]),s._v(" "),a("p",[s._v("创建一个新的Conda环境， 命名为tf2.0")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("conda create -n tf2.0\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("进入到tf2.0环境")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("conda activate tf2.0\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("安装pip")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("conda "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("install")]),s._v(" pip\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("检查Python和pip的版本\n需要满足"),a("code",[s._v("Python > 3.4 and pip >= 19.0")])]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("python3 --version\npip --version\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("开始安装tf2.0")]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("pip install tensorflow-gpu==2.0\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("h2",{attrs:{id:"一些常用的函数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一些常用的函数"}},[s._v("#")]),s._v(" 一些常用的函数")]),s._v(" "),a("ol",[a("li",[a("code",[s._v("tf.nn.softplus(features, name=None)")])])]),s._v(" "),a("p",[a("span",{staticClass:"katex-display"},[a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",[a("semantics",[a("mrow",[a("mi",[s._v("f")]),a("mo",[s._v("(")]),a("mi",[s._v("x")]),a("mo",[s._v(")")]),a("mo",[s._v("=")]),a("mi",[s._v("ln")]),a("mo",[s._v("(")]),a("mn",[s._v("1")]),a("mo",[s._v("+")]),a("msup",[a("mi",[s._v("e")]),a("mi",[s._v("x")])],1),a("mo",[s._v(")")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[s._v("f(x) = \\ln (1+e^x)\n")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"strut",staticStyle:{height:"0.75em"}}),a("span",{staticClass:"strut bottom",staticStyle:{height:"1em","vertical-align":"-0.25em"}}),a("span",{staticClass:"base displaystyle textstyle uncramped"},[a("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.10764em"}},[s._v("f")]),a("span",{staticClass:"mopen"},[s._v("(")]),a("span",{staticClass:"mord mathit"},[s._v("x")]),a("span",{staticClass:"mclose"},[s._v(")")]),a("span",{staticClass:"mrel"},[s._v("=")]),a("span",{staticClass:"mop"},[s._v("ln")]),a("span",{staticClass:"mopen"},[s._v("(")]),a("span",{staticClass:"mord mathrm"},[s._v("1")]),a("span",{staticClass:"mbin"},[s._v("+")]),a("span",{staticClass:"mord"},[a("span",{staticClass:"mord mathit"},[s._v("e")]),a("span",{staticClass:"vlist"},[a("span",{staticStyle:{top:"-0.413em","margin-right":"0.05em"}},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"0em"}},[s._v("​")])]),a("span",{staticClass:"reset-textstyle scriptstyle uncramped"},[a("span",{staticClass:"mord mathit"},[s._v("x")])])]),a("span",{staticClass:"baseline-fix"},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"0em"}},[s._v("​")])]),s._v("​")])])]),a("span",{staticClass:"mclose"},[s._v(")")])])])])])]),s._v(" "),a("p",{attrs:{align:"center"}},[a("img",{attrs:{src:"/images/python/daily_python/tensorflow/softplus.svg",width:"50%"}})]),s._v(" "),a("ol",{attrs:{start:"2"}},[a("li",[a("code",[s._v("tf.contrib.distributions.Normal")])])]),s._v(" "),a("p",[a("span",{staticClass:"katex-display"},[a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",[a("semantics",[a("mrow",[a("mi",[s._v("f")]),a("mrow",[a("mo",{attrs:{fence:"true"}},[s._v("(")]),a("mi",[s._v("x")]),a("mi",{attrs:{mathvariant:"normal"}},[s._v("∣")]),a("mi",[s._v("μ")]),a("mo",{attrs:{separator:"true"}},[s._v(",")]),a("msup",[a("mi",[s._v("σ")]),a("mrow",[a("mn",[s._v("2")])],1)],1),a("mo",{attrs:{fence:"true"}},[s._v(")")])],1),a("mo",[s._v("=")]),a("mfrac",[a("mrow",[a("mn",[s._v("1")])],1),a("mrow",[a("msqrt",[a("mrow",[a("mn",[s._v("2")]),a("mi",[s._v("π")]),a("msup",[a("mi",[s._v("σ")]),a("mrow",[a("mn",[s._v("2")])],1)],1)],1)],1)],1)],1),a("msup",[a("mi",[s._v("e")]),a("mrow",[a("mo",[s._v("−")]),a("mfrac",[a("mrow",[a("mo",[s._v("(")]),a("mi",[s._v("x")]),a("mo",[s._v("−")]),a("mi",[s._v("μ")]),a("msup",[a("mo",[s._v(")")]),a("mrow",[a("mn",[s._v("2")])],1)],1)],1),a("mrow",[a("mn",[s._v("2")]),a("msup",[a("mi",[s._v("σ")]),a("mrow",[a("mn",[s._v("2")])],1)],1)],1)],1)],1)],1)],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[s._v("f\\left(x | \\mu, \\sigma^{2}\\right)=\\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} e^{-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}}\n")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"strut",staticStyle:{height:"1.32319em"}}),a("span",{staticClass:"strut bottom",staticStyle:{height:"2.25319em","vertical-align":"-0.9300000000000002em"}}),a("span",{staticClass:"base displaystyle textstyle uncramped"},[a("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.10764em"}},[s._v("f")]),a("span",{staticClass:"minner displaystyle textstyle uncramped"},[a("span",{staticClass:"style-wrap reset-textstyle textstyle uncramped",staticStyle:{top:"0em"}},[a("span",{staticClass:"delimsizing size1"},[s._v("(")])]),a("span",{staticClass:"mord mathit"},[s._v("x")]),a("span",{staticClass:"mord mathrm"},[s._v("∣")]),a("span",{staticClass:"mord mathit"},[s._v("μ")]),a("span",{staticClass:"mpunct"},[s._v(",")]),a("span",{staticClass:"mord"},[a("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.03588em"}},[s._v("σ")]),a("span",{staticClass:"vlist"},[a("span",{staticStyle:{top:"-0.413em","margin-right":"0.05em"}},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"0em"}},[s._v("​")])]),a("span",{staticClass:"reset-textstyle scriptstyle uncramped"},[a("span",{staticClass:"mord scriptstyle uncramped"},[a("span",{staticClass:"mord mathrm"},[s._v("2")])])])]),a("span",{staticClass:"baseline-fix"},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"0em"}},[s._v("​")])]),s._v("​")])])]),a("span",{staticClass:"style-wrap reset-textstyle textstyle uncramped",staticStyle:{top:"0em"}},[a("span",{staticClass:"delimsizing size1"},[s._v(")")])])]),a("span",{staticClass:"mrel"},[s._v("=")]),a("span",{staticClass:"mord reset-textstyle displaystyle textstyle uncramped"},[a("span",{staticClass:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"}),a("span",{staticClass:"mfrac"},[a("span",{staticClass:"vlist"},[a("span",{staticStyle:{top:"0.8450540000000002em"}},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"1em"}},[s._v("​")])]),a("span",{staticClass:"reset-textstyle textstyle cramped"},[a("span",{staticClass:"mord textstyle cramped"},[a("span",{staticClass:"sqrt mord"},[a("span",{staticClass:"sqrt-sign",staticStyle:{top:"-0.11505399999999999em"}},[a("span",{staticClass:"style-wrap reset-textstyle textstyle uncramped"},[s._v("√")])]),a("span",{staticClass:"vlist"},[a("span",{staticStyle:{top:"0em"}},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"1em"}},[s._v("​")])]),a("span",{staticClass:"mord textstyle cramped"},[a("span",{staticClass:"mord mathrm"},[s._v("2")]),a("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.03588em"}},[s._v("π")]),a("span",{staticClass:"mord"},[a("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.03588em"}},[s._v("σ")]),a("span",{staticClass:"vlist"},[a("span",{staticStyle:{top:"-0.289em","margin-right":"0.05em"}},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"0em"}},[s._v("​")])]),a("span",{staticClass:"reset-textstyle scriptstyle cramped"},[a("span",{staticClass:"mord scriptstyle cramped"},[a("span",{staticClass:"mord mathrm"},[s._v("2")])])])]),a("span",{staticClass:"baseline-fix"},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"0em"}},[s._v("​")])]),s._v("​")])])])])]),a("span",{staticStyle:{top:"-0.875054em"}},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"1em"}},[s._v("​")])]),a("span",{staticClass:"reset-textstyle textstyle uncramped sqrt-line"})]),a("span",{staticClass:"baseline-fix"},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"1em"}},[s._v("​")])]),s._v("​")])])])])])]),a("span",{staticStyle:{top:"-0.22999999999999998em"}},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"1em"}},[s._v("​")])]),a("span",{staticClass:"reset-textstyle textstyle uncramped frac-line"})]),a("span",{staticStyle:{top:"-0.677em"}},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"1em"}},[s._v("​")])]),a("span",{staticClass:"reset-textstyle textstyle uncramped"},[a("span",{staticClass:"mord textstyle uncramped"},[a("span",{staticClass:"mord mathrm"},[s._v("1")])])])]),a("span",{staticClass:"baseline-fix"},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"1em"}},[s._v("​")])]),s._v("​")])])]),a("span",{staticClass:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"})]),a("span",{staticClass:"mord"},[a("span",{staticClass:"mord mathit"},[s._v("e")]),a("span",{staticClass:"vlist"},[a("span",{staticStyle:{top:"-0.45947000000000005em","margin-right":"0.05em"}},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"0em"}},[s._v("​")])]),a("span",{staticClass:"reset-textstyle scriptstyle uncramped"},[a("span",{staticClass:"mord scriptstyle uncramped"},[a("span",{staticClass:"mord"},[s._v("−")]),a("span",{staticClass:"mord reset-scriptstyle scriptstyle uncramped"},[a("span",{staticClass:"sizing reset-size5 size5 reset-scriptstyle textstyle uncramped nulldelimiter"}),a("span",{staticClass:"mfrac"},[a("span",{staticClass:"vlist"},[a("span",{staticStyle:{top:"0.5024571428571429em"}},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"0em"}},[s._v("​")])]),a("span",{staticClass:"reset-scriptstyle scriptscriptstyle cramped"},[a("span",{staticClass:"mord scriptscriptstyle cramped"},[a("span",{staticClass:"mord mathrm"},[s._v("2")]),a("span",{staticClass:"mord"},[a("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.03588em"}},[s._v("σ")]),a("span",{staticClass:"vlist"},[a("span",{staticStyle:{top:"-0.289em","margin-right":"0.1em"}},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"0em"}},[s._v("​")])]),a("span",{staticClass:"reset-scriptscriptstyle scriptscriptstyle cramped"},[a("span",{staticClass:"mord scriptscriptstyle cramped"},[a("span",{staticClass:"mord mathrm"},[s._v("2")])])])]),a("span",{staticClass:"baseline-fix"},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"0em"}},[s._v("​")])]),s._v("​")])])])])])]),a("span",{staticStyle:{top:"-0.22142857142857142em"}},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"0em"}},[s._v("​")])]),a("span",{staticClass:"reset-scriptstyle textstyle uncramped frac-line"})]),a("span",{staticStyle:{top:"-0.5142857142857143em"}},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"0em"}},[s._v("​")])]),a("span",{staticClass:"reset-scriptstyle scriptscriptstyle uncramped"},[a("span",{staticClass:"mord scriptscriptstyle uncramped"},[a("span",{staticClass:"mopen"},[s._v("(")]),a("span",{staticClass:"mord mathit"},[s._v("x")]),a("span",{staticClass:"mbin"},[s._v("−")]),a("span",{staticClass:"mord mathit"},[s._v("μ")]),a("span",{staticClass:"mclose"},[a("span",{staticClass:"mclose"},[s._v(")")]),a("span",{staticClass:"vlist"},[a("span",{staticStyle:{top:"-0.363em","margin-right":"0.1em"}},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"0em"}},[s._v("​")])]),a("span",{staticClass:"reset-scriptscriptstyle scriptscriptstyle uncramped"},[a("span",{staticClass:"mord scriptscriptstyle uncramped"},[a("span",{staticClass:"mord mathrm"},[s._v("2")])])])]),a("span",{staticClass:"baseline-fix"},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"0em"}},[s._v("​")])]),s._v("​")])])])])])]),a("span",{staticClass:"baseline-fix"},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"0em"}},[s._v("​")])]),s._v("​")])])]),a("span",{staticClass:"sizing reset-size5 size5 reset-scriptstyle textstyle uncramped nulldelimiter"})])])])]),a("span",{staticClass:"baseline-fix"},[a("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[a("span",{staticStyle:{"font-size":"0em"}},[s._v("​")])]),s._v("​")])])])])])])])]),s._v(" "),a("p",{attrs:{align:"center"}},[a("img",{attrs:{src:"/images/python/daily_python/tensorflow/Normal_Distribution_PDF.svg",width:"50%"}})]),s._v(" "),a("p",[s._v("The probability density function (pdf) is,")]),s._v(" "),a("div",{staticClass:"language-none line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("pdf(x; mu, sigma) = exp(-0.5 (x - mu)**2 / sigma**2) / Z\nZ = (2 pi sigma**2)**0.5\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("where "),a("code",[s._v("loc = mu")]),s._v(" is the mean, "),a("code",[s._v("scale = sigma")]),s._v(" is the std. deviation, and, "),a("code",[s._v("Z")]),s._v("\nis the normalization constant.")]),s._v(" "),a("p",[s._v("标准差 "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",[a("semantics",[a("mrow",[a("mi",[s._v("σ")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[s._v("\\sigma")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"strut",staticStyle:{height:"0.43056em"}}),a("span",{staticClass:"strut bottom",staticStyle:{height:"0.43056em","vertical-align":"0em"}}),a("span",{staticClass:"base textstyle uncramped"},[a("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.03588em"}},[s._v("σ")])])])]),s._v(" 是方差的算术平方根,不能是负数。")]),s._v(" "),a("ol",{attrs:{start:"3"}},[a("li",[a("code",[s._v("tf.squeeze()")]),s._v("\n下面有个例子:")])]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" tensorflow "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" tf\ntf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("enable_eager_execution"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("##if using TF1.4 for TF2.0 eager mode is the default mode.")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("####example 1")]),s._v("\na "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("constant"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("value"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("shape"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nOutput "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Tensor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" shape"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dtype"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("int32"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#after applying tf.squeeze shape has been changed from  (4,1) to (4, )")]),s._v("\nb "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("squeeze"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("input")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\noutput"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Tensor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" shape"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dtype"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("int32"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("####example2")]),s._v("\na "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("constant"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("value"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" shape"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nOutput"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Tensor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" shape"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dtype"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("int32"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#after applying tf.squeeze shape has been chnaged from (3, 1, 2) to (3, 2)")]),s._v("\nb "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("squeeze"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("input")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nOutput"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Tensor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" shape"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dtype"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("int32"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br")])]),a("p",[a("a",{attrs:{href:"https://stackoverflow.com/questions/41482823/what-do-the-functions-tf-squeeze-and-tf-nn-rnn-do",target:"_blank",rel:"noopener noreferrer"}},[s._v("stackoverflow"),a("OutboundLink")],1)])])}),[],!1,null,null,null);t.default=e.exports}}]);